# ðŸš€ Quick Start Guide - Jan-Gana-Drishti Dashboard

## For Data Scientists & Analysts

### ðŸ“‹ What You Got

A complete, production-ready Streamlit dashboard with 4 analytical modules:

1. **ETL Pipeline** - Cleans dirty state names using fuzzy matching
2. **Fraud Detection** - Benford's Law + Isolation Forest ML
3. **Migration Tracking** - Population movement analysis  
4. **Child Welfare** - MBU risk identification

---

## âš¡ Quick Launch (3 Steps)

### Step 1: Install Dependencies
```bash
cd /home/jdsb/Desktop/BiULding/Hackathons/UIDAI
pip install -r requirements.txt
```

### Step 2: Verify Data Structure
Make sure you have:
```
data/
â”œâ”€â”€ api_data_aadhar_biometric/  (CSV files)
â”œâ”€â”€ api_data_aadhar_demographic/ (CSV files)
â””â”€â”€ api_data_aadhar_enrolment/   (CSV files)
```

### Step 3: Launch Dashboard
```bash
# Option A: Use the launcher script
./run_dashboard.sh

# Option B: Direct Streamlit command
streamlit run app.py
```

Dashboard opens at: **http://localhost:8501**

---

## ðŸ§ª Testing Individual Modules

You can test each module independently:

### Test ETL Pipeline
```python
from modules.etl_pipeline import load_and_clean_data

# Load and clean data
merged_data, pipeline = load_and_clean_data()

# Check results
print(f"Total records: {len(merged_data):,}")
print(f"States: {merged_data['state'].nunique()}")
print(f"Districts: {merged_data['district'].nunique()}")
print("\nState mapping (first 10):")
for dirty, clean in list(pipeline.get_state_mapping().items())[:10]:
    print(f"  {dirty} â†’ {clean}")
```

### Test Fraud Detection
```python
from modules.fraud_detection import GhostHunterEngine

# Initialize (requires merged data from ETL)
fraud_engine = GhostHunterEngine(merged_data)

# Run Benford's Law test
benford_results = fraud_engine.benford_law_test()
print(f"\nHigh Risk Districts: {len(benford_results[benford_results['risk_level'] == 'HIGH RISK'])}")

# Run Isolation Forest
isolation_results = fraud_engine.isolation_forest_anomalies()

# Get top suspects
combined = fraud_engine.get_top_fraud_suspects(n=10)
print("\nTop 10 Fraud Suspects:")
print(combined[['state', 'district', 'risk_score']].head(10))
```

### Test Migration Tracker
```python
from modules.migration_tracker import MigrationPulseTracker

migration = MigrationPulseTracker(merged_data)
results = migration.run_full_analysis()

# View results
print("\nTop In-Migration Districts:")
print(results['district_scores'].nlargest(10, 'in_migration_score')[
    ['district', 'state', 'in_migration_score']
])
```

### Test Child Welfare
```python
from modules.child_welfare import ChildWelfareAnalyzer

welfare = ChildWelfareAnalyzer(merged_data)
results = welfare.run_full_analysis()

# View red districts
print("\nCritical Risk Districts:")
print(results['red_districts'][['district', 'state', 'child_mbu_rate', 'mbu_shortfall']])
```

---

## ðŸŽ¨ Dashboard Navigation

### Page 1: Executive Summary
- **KPIs:** Total districts, enrolments, fraud alerts, welfare risks
- **Charts:** Monthly trends, state-wise distribution
- **Insights:** Key policy implications

### Page 2: Fraud Detection
- **Tab 1:** Combined risk scores (Benford + ML)
- **Tab 2:** Benford's Law details
- **Tab 3:** Isolation Forest anomalies

### Page 3: Migration Heatmap
- **Tab 1:** State/district migration intensity map
- **Tab 2:** In-migration vs out-migration analytics
- **Tab 3:** Temporal trends month-by-month

### Page 4: Child Welfare
- **Tab 1:** Red districts (lowest MBU rates)
- **Tab 2:** Child vs adult MBU comparison
- **Tab 3:** Intervention priority matrix

---

## ðŸ”§ Customization Tips

### Change Color Scheme
Edit `app.py`, modify the CSS in `st.markdown()`:
```python
.main-header {
    background: linear-gradient(90deg, #FF9933 0%, #FFFFFF 50%, #138808 100%);
    # Change these hex colors
}
```

### Adjust Fraud Detection Sensitivity
In `modules/fraud_detection.py`:
```python
# Benford's Law - Line ~90
if chi_square > critical_value * 1.5:  # Change 1.5 to adjust
    risk_level = "HIGH RISK"

# Isolation Forest - Line ~145
iso_forest = IsolationForest(
    contamination=0.05,  # Change 0.05 (5% anomalies) to adjust
    ...
)
```

### Modify Migration Thresholds
In `modules/migration_tracker.py`, Line ~60:
```python
if row['in_migration_score'] > 20 and row['net_migration_score'] > 5:
    # Adjust 20 and 5 based on your data distribution
```

### Change Child Welfare Risk Levels
In `modules/child_welfare.py`, Line ~79:
```python
if row['child_mbu_percentile'] < 20 and row['mbu_shortfall'] > 100:
    # Adjust 20 (percentile) and 100 (shortfall) thresholds
```

---

## ðŸ“Š Export Results

### Export to CSV
```python
# In Python console after loading data
merged_data.to_csv('cleaned_data.csv', index=False)

# Export specific analysis
benford_results.to_csv('fraud_suspects.csv', index=False)
migration_results['district_scores'].to_csv('migration_scores.csv', index=False)
welfare_results['red_districts'].to_csv('red_districts.csv', index=False)
```

### Export Visualizations
In Streamlit dashboard, each Plotly chart has a download button (camera icon) for PNG export.

---

## ðŸ› Troubleshooting

### Issue: "Module not found" error
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

### Issue: "No CSV files found"
Check your data directory structure:
```bash
ls -R data/
# Should show subdirectories with CSV files
```

### Issue: Dashboard takes too long to load
- **Normal:** 1-2 minutes on first load (processing 5M+ records)
- **Speed up:** Use Polars instead of Pandas (edit `etl_pipeline.py`)

### Issue: Memory error
- **Reduce data:** Use fewer CSV files for testing
- **Increase RAM:** Process data in chunks (modify `load_csv_files()`)

### Issue: State name cleaning not working
Check fuzzy matching threshold in `modules/etl_pipeline.py`, Line ~70:
```python
if score > 75:  # Lower from 75 to 70 for more lenient matching
```

---

## ðŸ“ˆ Performance Optimization

### Use Caching (Already Implemented)
The dashboard uses `@st.cache_data` to avoid reprocessing. To clear cache:
- Press `C` in the Streamlit interface
- Or delete `.streamlit/cache/`

### Process Subset for Testing
Modify `etl_pipeline.py`, Line ~40:
```python
for file in csv_files[:2]:  # Process only first 2 files
    df = pd.read_csv(file)
    ...
```

### Use Polars (Faster than Pandas)
Replace Pandas with Polars in `etl_pipeline.py`:
```python
import polars as pl

# Instead of:
df = pd.read_csv(file)

# Use:
df = pl.read_csv(file).to_pandas()  # Convert back for compatibility
```

---

## ðŸŽ¯ Key Metrics Reference

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| **Benford Deviation Factor** | `chi_square / critical_value` | >1.5 = High fraud risk |
| **Migration Intensity** | `in_score + out_score` | >15 = High mobility |
| **Child MBU Rate** | `bio_updates / enrolments * 100` | <40% = Critical risk |
| **MBU Gap** | `adult_rate - child_rate` | >50% = Children lagging |
| **Anomaly Score** | `Isolation Forest score` | <-0.5 = Anomaly |

---

## ðŸ“ž Need Help?

1. **Check README.md** - Full documentation
2. **Check module docstrings** - Each function is documented
3. **Console logs** - Terminal shows processing steps
4. **Streamlit debug** - Add `st.write()` to debug

---

## âœ… Pre-Submission Checklist

- [ ] All dependencies installed (`pip install -r requirements.txt`)
- [ ] Data files in correct directories
- [ ] Dashboard launches without errors
- [ ] All 4 modules render correctly
- [ ] Visualizations display properly
- [ ] Export to CSV works
- [ ] README.md reviewed
- [ ] Code is commented
- [ ] No PII in sample outputs

---

## ðŸ† Hackathon Presentation Tips

### Demo Flow (10 minutes)
1. **Start with Executive Summary** (2 min)
   - Show KPIs, national trends
   
2. **Fraud Detection** (3 min)
   - Show Benford violators
   - Highlight dual-detection districts
   - Explain policy impact (subsidy leakage)

3. **Migration Heatmap** (2 min)
   - Show top in/out migration districts
   - Explain infrastructure needs

4. **Child Welfare** (3 min)
   - Show red districts
   - Intervention priority matrix
   - Policy recommendations

### Key Talking Points
- âœ… **Data Quality:** Solved state name issue with fuzzy matching (62â†’36 states)
- âœ… **Innovation:** Dual-method fraud detection (statistical + ML)
- âœ… **Impact:** Direct policy recommendations for each module
- âœ… **Scale:** Handles 5M+ records efficiently
- âœ… **Production-Ready:** Modular, cached, well-documented

---

**Good luck with the hackathon! ðŸ‡®ðŸ‡³ðŸš€**
